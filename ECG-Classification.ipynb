{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "import itertools\n",
    "import collections\n",
    "import pandas as pd\n",
    "import random\n",
    "import plotly.offline as offline\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Label</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21-MAR-17</td>\n",
       "      <td>24-MAR-17</td>\n",
       "      <td>E06_Baseline_Time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12-APR-17</td>\n",
       "      <td>15-APR-17</td>\n",
       "      <td>E06_Peak_Time</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27-JUL-16</td>\n",
       "      <td>30-JUL-16</td>\n",
       "      <td>E30_Baseline_Time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19-AUG-16</td>\n",
       "      <td>22-AUG-16</td>\n",
       "      <td>E30_Peak_Time</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10-JAN-17</td>\n",
       "      <td>13-JAN-17</td>\n",
       "      <td>E07B_Baseline_Time</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27-JAN-17</td>\n",
       "      <td>30-JAN-17</td>\n",
       "      <td>E07B_Peak_Time</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Start        End               Label  Class\n",
       "0  21-MAR-17  24-MAR-17   E06_Baseline_Time      1\n",
       "1  12-APR-17  15-APR-17       E06_Peak_Time      0\n",
       "2  27-JUL-16  30-JUL-16   E30_Baseline_Time      1\n",
       "3  19-AUG-16  22-AUG-16       E30_Peak_Time      0\n",
       "4  10-JAN-17  13-JAN-17  E07B_Baseline_Time      1\n",
       "5  27-JAN-17  30-JAN-17      E07B_Peak_Time      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub</th>\n",
       "      <th>desc1</th>\n",
       "      <th>tel</th>\n",
       "      <th>dtype</th>\n",
       "      <th>desc2</th>\n",
       "      <th>id</th>\n",
       "      <th>Exp</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>Telemetry Collection from ECG Sensor for RIh16...</td>\n",
       "      <td>Telemetry</td>\n",
       "      <td>TEL_ECG</td>\n",
       "      <td>Telemetry Collection from ECG Sensor</td>\n",
       "      <td>1912</td>\n",
       "      <td>E06</td>\n",
       "      <td>RIh16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201</td>\n",
       "      <td>Telemetry Collection from ECG Sensor for RTe16...</td>\n",
       "      <td>Telemetry</td>\n",
       "      <td>TEL_ECG</td>\n",
       "      <td>Telemetry Collection from ECG Sensor</td>\n",
       "      <td>1915</td>\n",
       "      <td>E06</td>\n",
       "      <td>RTe16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206</td>\n",
       "      <td>Telemetry Collection from ECG Sensor for RCl15...</td>\n",
       "      <td>Telemetry</td>\n",
       "      <td>TEL_ECG</td>\n",
       "      <td>Telemetry Collection from ECG Sensor</td>\n",
       "      <td>1916</td>\n",
       "      <td>E06</td>\n",
       "      <td>RCl15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "      <td>Telemetry Collection from ECG Sensor for RUf16...</td>\n",
       "      <td>Telemetry</td>\n",
       "      <td>TEL_ECG</td>\n",
       "      <td>Telemetry Collection from ECG Sensor</td>\n",
       "      <td>1918</td>\n",
       "      <td>E06</td>\n",
       "      <td>RUf16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>220</td>\n",
       "      <td>Telemetry Collection from ECG Sensor for 12C13...</td>\n",
       "      <td>Telemetry</td>\n",
       "      <td>TEL_ECG</td>\n",
       "      <td>Telemetry Collection from ECG Sensor</td>\n",
       "      <td>1401</td>\n",
       "      <td>E07B</td>\n",
       "      <td>12C136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sub                                              desc1        tel    dtype  \\\n",
       "0  196  Telemetry Collection from ECG Sensor for RIh16...  Telemetry  TEL_ECG   \n",
       "1  201  Telemetry Collection from ECG Sensor for RTe16...  Telemetry  TEL_ECG   \n",
       "2  206  Telemetry Collection from ECG Sensor for RCl15...  Telemetry  TEL_ECG   \n",
       "3  211  Telemetry Collection from ECG Sensor for RUf16...  Telemetry  TEL_ECG   \n",
       "4  220  Telemetry Collection from ECG Sensor for 12C13...  Telemetry  TEL_ECG   \n",
       "\n",
       "                                  desc2    id   Exp Species  \n",
       "0  Telemetry Collection from ECG Sensor  1912   E06   RIh16  \n",
       "1  Telemetry Collection from ECG Sensor  1915   E06   RTe16  \n",
       "2  Telemetry Collection from ECG Sensor  1916   E06   RCl15  \n",
       "3  Telemetry Collection from ECG Sensor  1918   E06   RUf16  \n",
       "4  Telemetry Collection from ECG Sensor  1401  E07B  12C136  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Exp_Timeline = pd.read_csv(\"/home/tao/jupyter3/Tel_Data/Exp_TimeLine.csv\")\n",
    "ECG_meta = pd.read_csv(\"/home/tao/jupyter3/Tel_Data/ECG_MetaInfor.csv\")\n",
    "display(Exp_Timeline)\n",
    "display(ECG_meta.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_H0 = list()\n",
    "Y_H0 = list()\n",
    "### Baseline\n",
    "for i in range(0, 13):\n",
    "    dd = \"/mnt/data0/tao/ECG/\" + ECG_meta.Exp[i] + \"/Baseline/\" + ECG_meta.Species[i]\n",
    "    file_hour = [x for x in os.listdir(dd) if '_H0_' in x]\n",
    "    for item in file_hour:\n",
    "        ff = dd + \"/\" + item\n",
    "        data = pd.read_csv(ff)\n",
    "        X_H0.append(list(data.VALUE.values))\n",
    "        Y_H0.append(0)\n",
    "### Peak\n",
    "for i in range(0, 13):\n",
    "    dd = \"/mnt/data0/tao/ECG/\" + ECG_meta.Exp[i] + \"/Peak/\" + ECG_meta.Species[i]\n",
    "    file_hour = [x for x in os.listdir(dd) if '_H0_' in x]\n",
    "    for item in file_hour:\n",
    "        ff = dd + \"/\" + item\n",
    "        data = pd.read_csv(ff)\n",
    "        X_H0.append(list(data.VALUE.values))\n",
    "        Y_H0.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9345, 10001)\n",
      "(9345,)\n"
     ]
    }
   ],
   "source": [
    "X_H0 = np.asarray(X_H0)\n",
    "Y_H0 = np.asarray(Y_H0)\n",
    "print(np.shape(X_H0))\n",
    "print(np.shape(Y_H0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline # : 3692\n",
      "Peak # : 5653\n"
     ]
    }
   ],
   "source": [
    "print('Baseline # :', len([x for x in Y_H0 if x == 0]))\n",
    "print('Peak # :', len([x for x in Y_H0 if x == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train :  8410\n",
      "x_test  :  935\n",
      "y_train :  Counter({1: 5074, 0: 3336})\n",
      "y_test  :  Counter({1: 579, 0: 356})\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_H0, Y_H0, test_size=0.1)\n",
    "\n",
    "print(\"x_train : \", len(x_train))\n",
    "print(\"x_test  : \", len(x_test))\n",
    "print(\"y_train : \", collections.Counter(y_train))\n",
    "print(\"y_test  : \", collections.Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10001,)\n",
      "(8410,)\n",
      "(935, 10001)\n",
      "(935,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train[0]))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_test))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpjk7j_5e6\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpjk7j_5e6', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f260e2e6898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpjk7j_5e6/model.ckpt.\n",
      "INFO:tensorflow:loss = 69.31474, step = 1\n",
      "INFO:tensorflow:global_step/sec: 129.652\n",
      "INFO:tensorflow:loss = 70.90298, step = 101 (0.773 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.211\n",
      "INFO:tensorflow:loss = 86.93245, step = 201 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.893\n",
      "INFO:tensorflow:loss = 76.2851, step = 301 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.311\n",
      "INFO:tensorflow:loss = 66.88684, step = 401 (0.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.771\n",
      "INFO:tensorflow:loss = 65.98689, step = 501 (0.993 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.518\n",
      "INFO:tensorflow:loss = 60.78144, step = 601 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.393\n",
      "INFO:tensorflow:loss = 66.28484, step = 701 (0.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.772\n",
      "INFO:tensorflow:loss = 68.609146, step = 801 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.374\n",
      "INFO:tensorflow:loss = 59.774292, step = 901 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.563\n",
      "INFO:tensorflow:loss = 56.906307, step = 1001 (0.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.439\n",
      "INFO:tensorflow:loss = 57.03872, step = 1101 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.603\n",
      "INFO:tensorflow:loss = 65.11074, step = 1201 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.996\n",
      "INFO:tensorflow:loss = 63.266525, step = 1301 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.91\n",
      "INFO:tensorflow:loss = 62.200817, step = 1401 (0.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.628\n",
      "INFO:tensorflow:loss = 56.215004, step = 1501 (0.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.81\n",
      "INFO:tensorflow:loss = 48.55052, step = 1601 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.23\n",
      "INFO:tensorflow:loss = 55.435406, step = 1701 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.685\n",
      "INFO:tensorflow:loss = 59.058365, step = 1801 (0.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.066\n",
      "INFO:tensorflow:loss = 66.13094, step = 1901 (0.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.166\n",
      "INFO:tensorflow:loss = 59.457855, step = 2001 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.585\n",
      "INFO:tensorflow:loss = 62.483673, step = 2101 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.187\n",
      "INFO:tensorflow:loss = 56.52081, step = 2201 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.975\n",
      "INFO:tensorflow:loss = 66.56522, step = 2301 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.025\n",
      "INFO:tensorflow:loss = 58.145298, step = 2401 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.767\n",
      "INFO:tensorflow:loss = 51.95647, step = 2501 (0.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.867\n",
      "INFO:tensorflow:loss = 61.592056, step = 2601 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.765\n",
      "INFO:tensorflow:loss = 60.28153, step = 2701 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.297\n",
      "INFO:tensorflow:loss = 58.18685, step = 2801 (0.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.221\n",
      "INFO:tensorflow:loss = 64.63698, step = 2901 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.795\n",
      "INFO:tensorflow:loss = 60.982082, step = 3001 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.651\n",
      "INFO:tensorflow:loss = 52.87242, step = 3101 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.525\n",
      "INFO:tensorflow:loss = 55.559578, step = 3201 (0.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.905\n",
      "INFO:tensorflow:loss = 58.96898, step = 3301 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.645\n",
      "INFO:tensorflow:loss = 54.27404, step = 3401 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.564\n",
      "INFO:tensorflow:loss = 58.72736, step = 3501 (0.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.37\n",
      "INFO:tensorflow:loss = 61.283154, step = 3601 (0.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.425\n",
      "INFO:tensorflow:loss = 67.17578, step = 3701 (0.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.687\n",
      "INFO:tensorflow:loss = 58.821747, step = 3801 (0.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.695\n",
      "INFO:tensorflow:loss = 61.930714, step = 3901 (0.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.815\n",
      "INFO:tensorflow:loss = 64.358696, step = 4001 (0.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.046\n",
      "INFO:tensorflow:loss = 58.46506, step = 4101 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.071\n",
      "INFO:tensorflow:loss = 53.67335, step = 4201 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.839\n",
      "INFO:tensorflow:loss = 64.321686, step = 4301 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.606\n",
      "INFO:tensorflow:loss = 58.217056, step = 4401 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.803\n",
      "INFO:tensorflow:loss = 60.08767, step = 4501 (0.654 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.714\n",
      "INFO:tensorflow:loss = 60.64534, step = 4601 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.553\n",
      "INFO:tensorflow:loss = 51.791294, step = 4701 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.119\n",
      "INFO:tensorflow:loss = 60.503323, step = 4801 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.19\n",
      "INFO:tensorflow:loss = 57.12288, step = 4901 (0.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.988\n",
      "INFO:tensorflow:loss = 68.06578, step = 5001 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.707\n",
      "INFO:tensorflow:loss = 56.453224, step = 5101 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.852\n",
      "INFO:tensorflow:loss = 54.830814, step = 5201 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.53\n",
      "INFO:tensorflow:loss = 54.586086, step = 5301 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.193\n",
      "INFO:tensorflow:loss = 60.03604, step = 5401 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.496\n",
      "INFO:tensorflow:loss = 60.253548, step = 5501 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.779\n",
      "INFO:tensorflow:loss = 61.883926, step = 5601 (0.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.363\n",
      "INFO:tensorflow:loss = 51.62812, step = 5701 (0.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.293\n",
      "INFO:tensorflow:loss = 60.89128, step = 5801 (0.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.654\n",
      "INFO:tensorflow:loss = 54.20547, step = 5901 (0.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.571\n",
      "INFO:tensorflow:loss = 52.769188, step = 6001 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.753\n",
      "INFO:tensorflow:loss = 57.404305, step = 6101 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.24\n",
      "INFO:tensorflow:loss = 51.375473, step = 6201 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.792\n",
      "INFO:tensorflow:loss = 54.8841, step = 6301 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.574\n",
      "INFO:tensorflow:loss = 57.26486, step = 6401 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.637\n",
      "INFO:tensorflow:loss = 63.87171, step = 6501 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.969\n",
      "INFO:tensorflow:loss = 55.613594, step = 6601 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.564\n",
      "INFO:tensorflow:loss = 62.798668, step = 6701 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.174\n",
      "INFO:tensorflow:loss = 55.817894, step = 6801 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.428\n",
      "INFO:tensorflow:loss = 53.913887, step = 6901 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.456\n",
      "INFO:tensorflow:loss = 61.53572, step = 7001 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.732\n",
      "INFO:tensorflow:loss = 55.423233, step = 7101 (0.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.811\n",
      "INFO:tensorflow:loss = 56.75744, step = 7201 (0.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 52.27883, step = 7301 (0.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.494\n",
      "INFO:tensorflow:loss = 59.902428, step = 7401 (0.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.044\n",
      "INFO:tensorflow:loss = 55.02206, step = 7501 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.858\n",
      "INFO:tensorflow:loss = 57.968773, step = 7601 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.516\n",
      "INFO:tensorflow:loss = 59.08509, step = 7701 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.668\n",
      "INFO:tensorflow:loss = 50.12422, step = 7801 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.002\n",
      "INFO:tensorflow:loss = 61.96545, step = 7901 (0.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.659\n",
      "INFO:tensorflow:loss = 60.32515, step = 8001 (0.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.747\n",
      "INFO:tensorflow:loss = 57.267853, step = 8101 (0.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.56\n",
      "INFO:tensorflow:loss = 60.599228, step = 8201 (0.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.143\n",
      "INFO:tensorflow:loss = 58.08236, step = 8301 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.184\n",
      "INFO:tensorflow:loss = 65.431564, step = 8401 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.069\n",
      "INFO:tensorflow:loss = 60.750557, step = 8501 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.385\n",
      "INFO:tensorflow:loss = 55.41663, step = 8601 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.017\n",
      "INFO:tensorflow:loss = 54.30147, step = 8701 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.746\n",
      "INFO:tensorflow:loss = 52.23993, step = 8801 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.312\n",
      "INFO:tensorflow:loss = 57.17261, step = 8901 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.708\n",
      "INFO:tensorflow:loss = 59.07757, step = 9001 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.579\n",
      "INFO:tensorflow:loss = 49.628048, step = 9101 (0.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.265\n",
      "INFO:tensorflow:loss = 56.207508, step = 9201 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.762\n",
      "INFO:tensorflow:loss = 56.954422, step = 9301 (0.690 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.585\n",
      "INFO:tensorflow:loss = 50.821472, step = 9401 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.959\n",
      "INFO:tensorflow:loss = 56.386383, step = 9501 (0.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.999\n",
      "INFO:tensorflow:loss = 59.285275, step = 9601 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.829\n",
      "INFO:tensorflow:loss = 58.305767, step = 9701 (0.663 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.425\n",
      "INFO:tensorflow:loss = 53.516594, step = 9801 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.927\n",
      "INFO:tensorflow:loss = 53.086613, step = 9901 (0.654 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmpjk7j_5e6/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 49.49803.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-02-12-16:10:57\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpjk7j_5e6/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-02-12-16:10:58\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.5176471, accuracy_baseline = 0.61497325, auc = 0.49566668, auc_precision_recall = 0.6295595, average_loss = 0.9713864, global_step = 10000, label/mean = 0.61497325, loss = 9.662194, precision = 0.6068966, prediction/mean = 0.57907796, recall = 0.6121739\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/tmpjk7j_5e6/model.ckpt-10000\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "x_train = normalize(x_train, axis=0, norm='max')\n",
    "x_test = normalize(x_test, axis=0, norm='max')\n",
    "\n",
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.feature_column.numeric_column(\"ecg\", shape=np.shape(x_train[0]))]\n",
    "\n",
    "# Build Classifier\n",
    "estimator = tf.estimator.LinearClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    n_classes=2,\n",
    "    optimizer=tf.train.FtrlOptimizer(\n",
    "      learning_rate=0.1,\n",
    "      l1_regularization_strength=0.001\n",
    "    )\n",
    ")\n",
    "\n",
    "# Train model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"ecg\": np.array(x_train)},\n",
    "    y=np.array(y_train),\n",
    "    batch_size=100,\n",
    "    num_epochs=1000,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "estimator.train(input_fn=train_input_fn, steps=10000)\n",
    "\n",
    "# Evaluate accuracy\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"ecg\": np.array(x_test)},\n",
    "    y=np.array(y_test),\n",
    "    batch_size=10,\n",
    "    num_epochs=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "accuracy_score = estimator.evaluate(input_fn=test_input_fn)[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "pred_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"ecg\": np.array(x_test)},\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "predictions = estimator.predict(input_fn=pred_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        #cm[i, j] = 0 if np.isnan(cm[i, j]) else cm[i, j]\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpjk7j_5e6/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Test Accuracy: 51.764709%\n",
      "\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = list()\n",
    "for p in predictions:\n",
    "    pred.append(p[\"class_ids\"][0])\n",
    "    \n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "print(\"\\nTest Accuracy: {0:f}%\\n\".format(accuracy_score*100))\n",
    "plot_confusion_matrix(cm, classes, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Define the sequential model that is used to train.\n",
    "\n",
    "2. Set of neural network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train :  8410\n",
      "x_test  :  935\n",
      "y_train :  Counter({1: 5081, 0: 3329})\n",
      "y_test  :  Counter({1: 572, 0: 363})\n",
      "(10001,)\n",
      "(8410,)\n",
      "(935, 10001)\n",
      "(935,)\n"
     ]
    }
   ],
   "source": [
    "### Separate the dataset into training and testing.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_H0, Y_H0, test_size=0.1)\n",
    "print(\"x_train : \", len(x_train))\n",
    "print(\"x_test  : \", len(x_test))\n",
    "print(\"y_train : \", collections.Counter(y_train))\n",
    "print(\"y_test  : \", collections.Counter(y_test))\n",
    "## Print train & test\n",
    "print(np.shape(x_train[0]))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(x_test))\n",
    "print(np.shape(y_test))\n",
    "# Normalize\n",
    "# x_train = normalize(x_train, axis=0, norm='max')\n",
    "# x_test = normalize(x_test, axis=0, norm='max')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=2)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define F1 metric\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 128)               1280256   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 1,291,154\n",
      "Trainable params: 1,291,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Keras Sequential Models\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=10001, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compilation\n",
    "# For a binary classification problem\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8410/8410 [==============================] - 6s 763us/step - loss: 0.7376 - acc: 0.5154 - f1: 0.5442\n",
      "Epoch 2/20\n",
      "8410/8410 [==============================] - 1s 62us/step - loss: 0.7005 - acc: 0.5649 - f1: 0.5753\n",
      "Epoch 3/20\n",
      "8410/8410 [==============================] - 1s 61us/step - loss: 0.6889 - acc: 0.5826 - f1: 0.5889\n",
      "Epoch 4/20\n",
      "8410/8410 [==============================] - 1s 62us/step - loss: 0.6851 - acc: 0.5897 - f1: 0.5926\n",
      "Epoch 5/20\n",
      "8410/8410 [==============================] - 1s 62us/step - loss: 0.6793 - acc: 0.5954 - f1: 0.5982\n",
      "Epoch 6/20\n",
      "8410/8410 [==============================] - 1s 62us/step - loss: 0.6754 - acc: 0.5999 - f1: 0.6017\n",
      "Epoch 7/20\n",
      "8410/8410 [==============================] - 1s 61us/step - loss: 0.6730 - acc: 0.5986 - f1: 0.5997\n",
      "Epoch 8/20\n",
      "8410/8410 [==============================] - 1s 61us/step - loss: 0.6702 - acc: 0.6028 - f1: 0.6026\n",
      "Epoch 9/20\n",
      "8410/8410 [==============================] - 1s 61us/step - loss: 0.6719 - acc: 0.6060 - f1: 0.6054\n",
      "Epoch 10/20\n",
      "8410/8410 [==============================] - 1s 61us/step - loss: 0.6625 - acc: 0.6055 - f1: 0.6036\n",
      "Epoch 11/20\n",
      "8410/8410 [==============================] - 1s 63us/step - loss: 0.6638 - acc: 0.6070 - f1: 0.6060\n",
      "Epoch 12/20\n",
      "8410/8410 [==============================] - 1s 63us/step - loss: 0.6562 - acc: 0.6131 - f1: 0.6126\n",
      "Epoch 13/20\n",
      "8410/8410 [==============================] - 1s 62us/step - loss: 0.6520 - acc: 0.6153 - f1: 0.6149\n",
      "Epoch 14/20\n",
      "8410/8410 [==============================] - 1s 62us/step - loss: 0.6307 - acc: 0.6329 - f1: 0.6319\n",
      "Epoch 15/20\n",
      "8410/8410 [==============================] - 1s 62us/step - loss: 0.6266 - acc: 0.6451 - f1: 0.6450\n",
      "Epoch 16/20\n",
      "8410/8410 [==============================] - 1s 62us/step - loss: 0.6204 - acc: 0.6518 - f1: 0.6513\n",
      "Epoch 17/20\n",
      "8410/8410 [==============================] - 1s 70us/step - loss: 0.6086 - acc: 0.6573 - f1: 0.6568\n",
      "Epoch 18/20\n",
      "8410/8410 [==============================] - 1s 80us/step - loss: 0.5936 - acc: 0.6756 - f1: 0.6752\n",
      "Epoch 19/20\n",
      "8410/8410 [==============================] - 1s 62us/step - loss: 0.5835 - acc: 0.6848 - f1: 0.6844\n",
      "Epoch 20/20\n",
      "8410/8410 [==============================] - 1s 63us/step - loss: 0.5789 - acc: 0.6922 - f1: 0.6916\n",
      "935/935 [==============================] - 0s 179us/step\n"
     ]
    }
   ],
   "source": [
    "## Run the model\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6378572471001569, 0.6449197872437258, 0.6438818117514014]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
